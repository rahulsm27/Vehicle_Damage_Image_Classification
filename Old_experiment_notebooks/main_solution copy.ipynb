{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yRL3JNr7AZE",
        "outputId": "9acc0b84-982b-4955-b4b3-8c65195450f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Collecting keras-efficientnet\n",
            "  Downloading keras_efficientnet-0.1.4-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: keras-efficientnet\n",
            "Successfully installed keras-efficientnet-0.1.4\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.2)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "#Installing libraries\n",
        "\n",
        "!pip3 install split-folders\n",
        "!pip3 install keras-efficientnet\n",
        "!pip3 install -U efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oOML4Zt17AZJ"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "\n",
        "colab = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if colab :\n",
        "  from google.colab import drive\n",
        "\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCmfI72h7EXL",
        "outputId": "71e55f13-554b-4dcf-ba4c-688dc86578f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UJGAanLD7AZK"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "  train_csv = pd.read_csv(\"/content/drive/MyDrive/hackathon/train/train.csv\")\n",
        "  test_csv =  pd.read_csv(\"/content/drive/MyDrive/hackathon/test/test.csv\")\n",
        "else:\n",
        "  train_csv = pd.read_csv(\"./train/train.csv\")\n",
        "  test_csv =  pd.read_csv(\"./test/test.csv\")\n",
        "\n",
        "labels = {1:'crack',2:'scratch',3:'tire flat',4 :'dent', 5: 'glass shatter', 6: 'lamp broken'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX4GGn4F7AZL",
        "outputId": "6336cbcb-5bac-4509-c988-6c68235cd6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_csv.shape=(7200, 3)\n",
            "test_csv.shape=(4800, 2)\n"
          ]
        }
      ],
      "source": [
        "# Checking number of records\n",
        "print(f\"{train_csv.shape=}\")\n",
        "print(f\"{test_csv.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WhONUUYy7AZL",
        "outputId": "5b6146fe-518e-496c-926e-70bdc6a67576"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id filename  label\n",
              "0         1    1.jpg      2\n",
              "1         2    2.jpg      4\n",
              "2         3    3.jpg      2\n",
              "3         4    4.jpg      3\n",
              "4         5    5.jpg      5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a101defc-8f1a-4b52-8daa-05682ac271ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a101defc-8f1a-4b52-8daa-05682ac271ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a101defc-8f1a-4b52-8daa-05682ac271ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a101defc-8f1a-4b52-8daa-05682ac271ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14aa448c-b93c-4b96-8341-c4888f655bb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14aa448c-b93c-4b96-8341-c4888f655bb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14aa448c-b93c-4b96-8341-c4888f655bb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Lets have a look at csv file\n",
        "train_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs_UDMyV7AZM",
        "outputId": "43bafad5-3599-4716-89fd-99d129d05816"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image_id     int64\n",
              "filename    object\n",
              "label        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_csv.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1DnAIiL7AZN",
        "outputId": "e51fff54-4f28-4661-8f65-a3d0a332845b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2349\n",
              "4    2079\n",
              "5    1185\n",
              "6     882\n",
              "3     534\n",
              "1     171\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Let us see number of data points for each labels\n",
        "train_csv['label'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zEhZPwUC7AZO"
      },
      "outputs": [],
      "source": [
        "# Define image folder path\n",
        "if colab:\n",
        "  path_to_train_images = \"/content/drive/MyDrive/hackathon/train/images/\"\n",
        "  path_to_test_images = \"/content/drive/MyDrive/hackathon/test/images/\"\n",
        "\n",
        "else:\n",
        "  path_to_train_images = \"./train/images/\"\n",
        "  path_to_test_images = \"./test/images/\"\n",
        "\n",
        "# Listing all images\n",
        "train_image_files = os.listdir(path_to_train_images)\n",
        "#test_image_files = os.listdir(path_to_test_images)\n",
        "\n",
        "train_image_files = [t for t in train_image_files if t.endswith(\".jpg\")]\n",
        "train_image_files=[t for t in train_image_files if '(' not in t]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q-nvkg3G7AZO"
      },
      "outputs": [],
      "source": [
        "# print(f\"{train_image_files=}\")\n",
        "# print(f\"{test_image_files=}\")\n",
        "#len(set(train_image_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fSeUj4qO7AZP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Check some images of train\n",
        "\n",
        "# for i,image_file in enumerate(train_image_files):\n",
        "#     if image_file.endswith(\".jpg\") or image_file.endswith(\".png\"):\n",
        "#         if i < 5:\n",
        "#             print('Labels : ' , f\"{labels[int(train_csv.loc[train_csv['filename'] == image_file]['label'])]}\")\n",
        "\n",
        "#             image = Image.open(path_to_train_images + image_file)\n",
        "#             display(image)\n",
        "\n",
        "#             print(\"-\"*50)\n",
        "\n",
        "#         else:\n",
        "#             break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2p9xNej7AZQ"
      },
      "outputs": [],
      "source": [
        "# # Let us find the maximum height and maximum weight in all images\n",
        "# train_max_width = -float('inf')\n",
        "# train_max_height = -float('inf')\n",
        "\n",
        "# train_min_width = float('inf')\n",
        "# train_min_height = float('inf')\n",
        "\n",
        "\n",
        "# for image_file in train_image_files:\n",
        "#     if image_file.endswith(\".jpg\") or image_file.endswith(\".png\"):\n",
        "#         image = Image.open(path_to_train_images + image_file)\n",
        "\n",
        "#         width, height = image.size\n",
        "\n",
        "#         train_max_height = max(height,train_max_height)\n",
        "#         train_max_width = max(width,train_max_width)\n",
        "\n",
        "#         train_min_width = min(height,train_max_height)\n",
        "#         train_min_height = min(height,train_max_height)\n",
        "\n",
        "# print(f\"{train_max_height=}\")\n",
        "\n",
        "# print(f\"{train_max_width=}\")\n",
        "\n",
        "# print(f\"{train_min_height=}\")\n",
        "\n",
        "# print(f\"{train_min_width=}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zE5CpXUcZgfC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XQiGLEz47AZR"
      },
      "outputs": [],
      "source": [
        "labels = {1:'crack',2:'scratch',3:'tire flat',4 :'dent', 5: 'glass shatter', 6: 'lamp broken'}\n",
        "folder = './dataset/train'\n",
        "train_image_files=[t for t in train_image_files if '(' not in t]\n",
        "\n",
        "#making folder for each classes\n",
        "for values in labels:\n",
        "    path = os.path.join(folder,str(values))\n",
        "    os.makedirs(path,exist_ok=True)\n",
        "\n",
        "# coping our raw data to each classes\n",
        "\n",
        "for image in train_image_files:\n",
        " #   print(image)\n",
        "    label = int((train_csv[train_csv['filename'] == image]['label']).iloc[0])\n",
        "  #  print(label)\n",
        "  #  path = os.path.join(folder,label,'/')\n",
        "    from_path = os.path.join(path_to_train_images,image)\n",
        "    to_path = os.path.join(folder,str(label))\n",
        "    if not os.path.exists(os.path.join(to_path,image)):\n",
        "      shutil.copy(from_path,to_path)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrjBjBSf7AZS",
        "outputId": "dcbc974b-3833-4d12-af42-3084ffe7160c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 7200 files [00:00, 19637.45 files/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import splitfolders\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(\"./dataset/train\", output=\"./dataset_final\",\n",
        "    seed=1337, ratio=(.8, .2, ), group_prefix=None, move=True) # default values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xlmdAI347AZT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7ms4WBmi7AZU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "IMG_SIZE = 600\n",
        "batch = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtNDUI3E7AZU",
        "outputId": "d647b072-5c9e-4e2d-9ec3-0c5fd3bc43bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5758 images belonging to 6 classes.\n",
            "Found 1442 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "\n",
        "train_dir = './dataset_final/train'\n",
        "validation_dir = './dataset_final/val'\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator()#rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = batch, class_mode = 'categorical', target_size = (IMG_SIZE , IMG_SIZE ))\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory( validation_dir, batch_size = batch, class_mode = 'categorical', target_size = (IMG_SIZE, IMG_SIZE))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkTXvgqW3kIf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    model = EfficientNetB7(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "-2eDfqWD3kF5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 6\n",
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n"
      ],
      "metadata": {
        "id": "pjqEtRbPebkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/ckpt/checkpoint.weights.h5'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "klIHmZ8jeR99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coAK_dFcIl8O",
        "outputId": "08b9b44f-3464-4434-ea5a-9bf8175da238"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 315s 6s/step - loss: 23.0180 - accuracy: 0.5906 - val_loss: 26.4810 - val_accuracy: 0.3856\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 283s 6s/step - loss: 17.3195 - accuracy: 0.6662 - val_loss: 16.8336 - val_accuracy: 0.4286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/models')"
      ],
      "metadata": {
        "id": "gCJve6koThdG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlOprXNIeQKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "hist = model.fit(train_generator, steps_per_epoch = 50,\n",
        "                 epochs=epochs, validation_data=validation_generator, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyJ1x3yaTFQu",
        "outputId": "f3c7225e-00a8-4c6d-9bb3-b43a2a76e8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 284s 6s/step - loss: 18.1087 - accuracy: 0.6756 - val_loss: 18.0587 - val_accuracy: 0.6255\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 263s 5s/step - loss: 16.9974 - accuracy: 0.6881 - val_loss: 30.0725 - val_accuracy: 0.4723\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 283s 6s/step - loss: 16.2975 - accuracy: 0.6862 - val_loss: 20.0632 - val_accuracy: 0.5368\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - ETA: 0s - loss: 14.6143 - accuracy: 0.7081"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbLUi2RXVtWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sRoIdE6VtO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 5 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-5:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 4\n",
        "hist = model.fit(train_generator, epochs=epochs, validation_data=validation_generator,callbacks=[model_checkpoint_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "0VojUXK9Il5d",
        "outputId": "99669670-6f34-41d7-b63b-73839f243315"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "90/90 [==============================] - 136s 1s/step - loss: 1.7295 - accuracy: 0.2954 - val_loss: 1.5970 - val_accuracy: 0.3259\n",
            "Epoch 2/4\n",
            "90/90 [==============================] - 134s 1s/step - loss: 1.6530 - accuracy: 0.3086 - val_loss: 1.5968 - val_accuracy: 0.3259\n",
            "Epoch 3/4\n",
            "90/90 [==============================] - 125s 1s/step - loss: 1.6225 - accuracy: 0.3154 - val_loss: 1.6004 - val_accuracy: 0.3259\n",
            "Epoch 4/4\n",
            "90/90 [==============================] - 123s 1s/step - loss: 1.6143 - accuracy: 0.3121 - val_loss: 1.6028 - val_accuracy: 0.3259\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5f1840e138cb>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplot_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_hist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RrO6OC9XIl2U",
        "outputId": "04ee5cba-937d-4dcb-ee85-04f613fee190"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model weights are saved at the end of every epoch, if it's the best seen\n",
        "# so far.\n",
        "#model.fit(epochs=EPOCHS, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "# The model weights (that are considered the best) can be loaded as -\n",
        "model.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "id": "w59jLvs7Ilzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGpOIhMhIlxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mv7PvR_GIlu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InHFmtviIlsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMBamtL7Ilpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsk1cAesIlmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jlltx_nHIlkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SQ5swnfIljF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LW-CQKppIlhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZblfgwdqIldW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxSO0BcsIlZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fX_cKTzvIlXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHyIrWfzIlUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x741A_G2IlSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LM_FjKc7IlPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9_FjXi0IlNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "class DataCallback(keras.callbacks.Callback):  # diff\n",
        "    \"\"\"Callback to operate on batch data from metric.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Offer a metric to access batch data.\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.y_true = None\n",
        "        self.y_pred = None\n",
        "        #self.metric = tf.keras.metrics.F1Score(threshold=0.5)\n",
        "\n",
        "\n",
        "    def set_model(self, model):\n",
        "        \"\"\"Initialize variables when model is set.\"\"\"\n",
        "        self.y_true = tf_nan(model.output.dtype)\n",
        "        self.y_pred = tf_nan(model.output.dtype)\n",
        "\n",
        "    def metric(self, y_true, y_pred):\n",
        "\n",
        "        print(y_true,y_pred)\n",
        "        \"\"\"Fake metric.\"\"\"\n",
        "        if self.y_true is None:\n",
        "          self.y_true.assign(y_true)\n",
        "          self.y_pred.assign(y_pred)\n",
        "        else:\n",
        "          self.y_true = tf.concat([self.y_true,y_true],axis=0)\n",
        "          self.y_pred = tf.concat([self.y_pred,y_pred],axis=0)\n",
        "\n",
        "        def create_one_hot_array(y_pred):\n",
        "        # Get the indices of the maximum values along each row\n",
        "          max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "          # Create a new array with zeros\n",
        "          one_hot_array = np.zeros_like(y_pred)\n",
        "\n",
        "          # Set 1 at the maximum value indices\n",
        "          one_hot_array[np.arange(len(y_pred)), max_indices] = 1\n",
        "\n",
        "          return one_hot_array\n",
        "\n",
        "             #   _logs ['f1_Score'] = metric\n",
        "        # print(\"y_true =\", y_true.numpy().shape)\n",
        "        # print(\"y_pred =\", y_pred.numpy().shape)\n",
        "\n",
        "        score = f1_score(self.y_true.numpy(),create_one_hot_array(self.y_pred.numpy()),average='macro')\n",
        "        #metric.update_state(y_true.nump\n",
        "        return score\n",
        "\n",
        "    def on_epoch_end(self, _batch, logs=None):\n",
        "        \"\"\"See keras.callbacks.Callback.on_train_batch_end.\"\"\"\n",
        "\n",
        "\n",
        "        def create_one_hot_array(y_pred):\n",
        "        # Get the indices of the maximum values along each row\n",
        "          max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "          # Create a new array with zeros\n",
        "          one_hot_array = np.zeros_like(y_pred)\n",
        "\n",
        "          # Set 1 at the maximum value indices\n",
        "          one_hot_array[np.arange(len(y_pred)), max_indices] = 1\n",
        "\n",
        "          return one_hot_array\n",
        "\n",
        "             #   _logs ['f1_Score'] = metric\n",
        "        print(\"y_true =\", self.y_true.numpy().shape)\n",
        "        print(\"y_pred =\", self.y_pred.numpy().shape)\n",
        "\n",
        "        score = f1_score(self.y_true.numpy(),create_one_hot_array(self.y_pred.numpy()),average='macro')\n",
        "        #metric.update_state(y_true.nump(), y_pred.numpy())\n",
        "        #result = metric.result()\n",
        "       # logs['f1_score'] = score\n",
        "        print('f1_score')\n",
        "        #return logs\n",
        "        #print\n",
        "        del self.y_true, self.y_pred\n",
        "\n",
        "\n",
        "\n",
        "    # def on_epoch_end(self, _logs=None):\n",
        "    #     \"\"\"Clean up.\"\"\"\n",
        "    #     del self.y_true, self.y_pred\n",
        "\n",
        "def tf_nan(dtype):\n",
        "  \"\"\"Create NaN variable of proper dtype and variable shape for assign().\"\"\"\n",
        "  return tf.Variable(float(\"nan\"), dtype=dtype, shape=tf.TensorShape(None))\n",
        "callback = DataCallback()"
      ],
      "metadata": {
        "id": "ISp0K9hN3kCu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTix8rp47AZW",
        "outputId": "2c7445b6-a6b0-4434-b625-6fe4a1bdd23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create the EfficientNetB0 model with pre-trained weights\n",
        "base_model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Flatten the output\n",
        "x = Flatten()(base_model.output)\n",
        "\n",
        "# Add additional layers on top of the flattened output\n",
        "x = Dense(1028, activation='relu')(x)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(6, activation='softmax')(x)\n",
        "\n",
        "# Create the full model\n",
        "full_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "full_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['categorical_accuracy',callback.metric])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "mrB1QAlw7AZW",
        "outputId": "1cbd74bb-3ade-43e7-8807-6c48187d9ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32) Tensor(\"model/dense_1/Softmax:0\", shape=(None, 6), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-81b845e8bf20>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mno_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m full_model.fit(train_generator,steps_per_epoch=3, validation_data = validation_generator,  \n\u001b[0m\u001b[1;32m      3\u001b[0m                              epochs = no_epochs, callbacks=[callback])\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.save(\"tmp.tf\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file6m97miw2.py\u001b[0m in \u001b[0;36mtf__metric\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     41\u001b[0m                             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval__1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_one_hot_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-18-e99f708aac3b>\", line 49, in metric  *\n        score = f1_score(self.y_true.numpy(),create_one_hot_array(self.y_pred.numpy()),average='macro')\n\n    AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n"
          ]
        }
      ],
      "source": [
        "no_epochs = 8\n",
        "full_model.fit(train_generator,steps_per_epoch=3, validation_data = validation_generator,\n",
        "                             epochs = no_epochs, callbacks=[callback])\n",
        "#model.save(\"tmp.tf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTGVZDOuoYls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbU4ue2LoYiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8A3rVbjPoYfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyw-mY1c7AZX",
        "outputId": "14c1abfd-64b8-4b04-ccf0-6e17e7d69b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4800 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "if colab:\n",
        "  test_dir = '/content/drive/MyDrive/hackathon/test'\n",
        "else:\n",
        "  test_dir = './test/'\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory( test_dir, batch_size = 20, class_mode = None, target_size = (224, 224))\n",
        "\n",
        "test_generator.reset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbIr0fhSIOg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WBkfb35IOd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CG3XWPlIObe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJAFQCkWIOZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VDrAzaIIOWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nBLGC1DIIOTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SUBMITING OUR PREDICTIONS"
      ],
      "metadata": {
        "id": "M1OnTqUGIO4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = full_model.predict(test_generator)\n",
        "\n",
        "predicted_class_indices=np.argmax(predictions,axis=1)\n",
        "labels_map = (train_generator.class_indices)\n",
        "labels_map = dict((v,k) for k,v in labels_map.items())\n",
        "predictions = [labels_map[i] for i in predicted_class_indices]\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIGuxmtnAq6G",
        "outputId": "d66d2327-90da-4d38-edad-5241dafdb191"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240/240 [==============================] - 57s 231ms/step\n",
            "['2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "-bcFuhNZ7AZX"
      },
      "outputs": [],
      "source": [
        "# Preparing submitssion file\n",
        "\n",
        "filenames=test_generator.filenames\n",
        "filenames = [f[7:] for f in filenames]\n",
        "results=pd.DataFrame({\"image_id\":filenames,\n",
        "                      \"label\":predictions})\n",
        "results.to_csv(\"sub.csv\",index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_tQRWWQ7AZY",
        "outputId": "fae800ce-5122-4d9a-9984-70612669fdad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5}"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3ajCZpSe7AZZ"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('/content/dataset')\n",
        "\n",
        "# shutil.rmtree('/content/dataset_final')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len( base_model.layers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLVl0xKNZ7xZ",
        "outputId": "95a837f4-d569-4076-e3cf-fc038ce14c22"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in base_model.layers:\n",
        "  print (layers)"
      ],
      "metadata": {
        "id": "g0o-zTxofbDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "class DataCallback(keras.callbacks.Callback):  # diff\n",
        "    \"\"\"Callback to operate on batch data from metric.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Offer a metric to access batch data.\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.y_true = None\n",
        "        self.y_pred = None\n",
        "        #self.metric = tf.keras.metrics.F1Score(threshold=0.5)\n",
        "\n",
        "\n",
        "    def set_model(self, model):\n",
        "        \"\"\"Initialize variables when model is set.\"\"\"\n",
        "        self.y_true = tf_nan(model.output.dtype)\n",
        "        self.y_pred = tf_nan(model.output.dtype)\n",
        "\n",
        "    def metric(self, y_true, y_pred):\n",
        "\n",
        "        print(y_true,y_pred)\n",
        "        \"\"\"Fake metric.\"\"\"\n",
        "        if self.y_true is None:\n",
        "          self.y_true.assign(y_true)\n",
        "          self.y_pred.assign(y_pred)\n",
        "        else:\n",
        "          self.y_true = tf.concat([self.y_true,y_true],axis=0)\n",
        "          self.y_pred = tf.concat([self.y_pred,y_pred],axis=0)\n",
        "\n",
        "        def create_one_hot_array(y_pred):\n",
        "        # Get the indices of the maximum values along each row\n",
        "          max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "          # Create a new array with zeros\n",
        "          one_hot_array = np.zeros_like(y_pred)\n",
        "\n",
        "          # Set 1 at the maximum value indices\n",
        "          one_hot_array[np.arange(len(y_pred)), max_indices] = 1\n",
        "\n",
        "          return one_hot_array\n",
        "\n",
        "             #   _logs ['f1_Score'] = metric\n",
        "        # print(\"y_true =\", y_true.numpy().shape)\n",
        "        # print(\"y_pred =\", y_pred.numpy().shape)\n",
        "\n",
        "        score = f1_score(y_true.numpy(),create_one_hot_array(y_pred.numpy()),average='macro')\n",
        "        #metric.update_state(y_true.nump\n",
        "        return score\n",
        "\n",
        "    def on_epoch_end(self, _batch, logs=None):\n",
        "        \"\"\"See keras.callbacks.Callback.on_train_batch_end.\"\"\"\n",
        "\n",
        "\n",
        "        def create_one_hot_array(y_pred):\n",
        "        # Get the indices of the maximum values along each row\n",
        "          max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "          # Create a new array with zeros\n",
        "          one_hot_array = np.zeros_like(y_pred)\n",
        "\n",
        "          # Set 1 at the maximum value indices\n",
        "          one_hot_array[np.arange(len(y_pred)), max_indices] = 1\n",
        "\n",
        "          return one_hot_array\n",
        "\n",
        "             #   _logs ['f1_Score'] = metric\n",
        "        print(\"y_true =\", self.y_true.numpy().shape)\n",
        "        print(\"y_pred =\", self.y_pred.numpy().shape)\n",
        "\n",
        "        score = f1_score(self.y_true.numpy(),create_one_hot_array(self.y_pred.numpy()),average='macro')\n",
        "        #metric.update_state(y_true.nump(), y_pred.numpy())\n",
        "        #result = metric.result()\n",
        "       # logs['f1_score'] = score\n",
        "        print('f1_score')\n",
        "        #return logs\n",
        "        #print\n",
        "        del self.y_true, self.y_pred\n",
        "\n",
        "\n",
        "\n",
        "    # def on_epoch_end(self, _logs=None):\n",
        "    #     \"\"\"Clean up.\"\"\"\n",
        "    #     del self.y_true, self.y_pred\n",
        "\n",
        "def tf_nan(dtype):\n",
        "  \"\"\"Create NaN variable of proper dtype and variable shape for assign().\"\"\"\n",
        "  return tf.Variable(float(\"nan\"), dtype=dtype, shape=tf.TensorShape(None))\n",
        "callback = DataCallback()"
      ],
      "metadata": {
        "id": "qLLrQ5yni0K_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6oOyg-ZnBFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}